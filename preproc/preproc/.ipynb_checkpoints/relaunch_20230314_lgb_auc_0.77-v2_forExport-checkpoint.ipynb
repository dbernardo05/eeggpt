{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0. operational\n",
    "# V1. add feature to allow export of EEG time locations that contain artifact.\n",
    "#         > first ARF is run, saves artifact locations into pd dataframe which contains, filename of data, \n",
    "#         > subsegment number of data, and artifact state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/mne/fixes.py:988: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(numba.__version__) < LooseVersion('0.40'):\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/mne/fixes.py:988: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(numba.__version__) < LooseVersion('0.40'):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "import fnmatch\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "from glob import glob\n",
    "from scipy import signal\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def get_cv(subjects):\n",
    "    cv = {}\n",
    "    \n",
    "    temp_fnames = []\n",
    "    temp_lbls = []\n",
    "    temp_anns = []\n",
    "    temp_idcs = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        base = '../data/%s/%s_' % (str(subject).zfill(3), str(subject).zfill(3))\n",
    "        fnames = sorted(glob(base + '*.h5'),\n",
    "                        key=lambda x: int(x.replace(base, '')[:-7]))\n",
    "\n",
    "        fnames_finals = []\n",
    "        for fname in fnames:\n",
    "            ba = '../data/%s/' % (str(subject).zfill(3))\n",
    "            fn = fname.replace(ba, '')\n",
    "            fnames_finals.append(fn)\n",
    "        temp_fnames.extend(fnames_finals)\n",
    "\n",
    "        for fname in fnames_finals:\n",
    "            temp_lbls.append(int(fname.split('.')[0][-1]))\n",
    "            anns = int(fname.split('.')[0].split('_')[2])\n",
    "            #print fname.split('.')[0].split('_')[2]\n",
    "            temp_anns.append(anns)\n",
    "            temp_idcs.append(True)\n",
    "\n",
    "    cv['fnames'] = np.array(temp_fnames)\n",
    "    cv['labels'] = np.array(temp_lbls)\n",
    "    cv['anns'] = np.array(temp_anns)\n",
    "    cv['indices'] = np.array(temp_idcs)\n",
    "\n",
    "    #print cv\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_chans = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', \n",
    "    'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz', 'A1', 'A2']  # Note temporal chain has different pattern!\n",
    "\n",
    "xforms = {\n",
    "            'original': ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz', 'A1', 'A2'],\n",
    "            'leftright': ['Fp2', 'Fp1', 'F4', 'F3', 'C4', 'C3', 'P4' , 'P3', 'O2', 'O1', 'F8', 'F7', 'T4', 'T3', 'T6', 'T5','Fz', 'Cz', 'Pz', 'A2', 'A1'],\n",
    "         'postant':    [ 'O1', 'O2', 'T3', 'T4', 'T5', 'T6',  'P4' , 'P3', 'C3', 'C4', 'Fz', 'Cz', 'Pz', 'A1', 'A2', 'Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8']\n",
    "}\n",
    "\n",
    "xform_map = []\n",
    "for xfn, xf_lst in xforms.items():\n",
    "    xform_map.append([ref_chans.index(xf_ch) for xf_ch in xf_lst])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: relative_log_power\n",
      "./features/relative_log_power/017.npz does not exist!\n",
      "./features/relative_log_power/021.npz does not exist!\n",
      "./features/relative_log_power/024.npz does not exist!\n",
      "./features/relative_log_power/027.npz does not exist!\n",
      "./features/relative_log_power/040.npz does not exist!\n",
      "\t\trelative_log_power shape: (5359, 30, 21, 6)\n",
      "\t: (160770, 126)\n",
      "Feature: stats\n",
      "./features/stats/017.npz does not exist!\n",
      "./features/stats/021.npz does not exist!\n",
      "./features/stats/024.npz does not exist!\n",
      "./features/stats/027.npz does not exist!\n",
      "./features/stats/040.npz does not exist!\n",
      "\t\tstats shape: (5359, 30, 21, 6)\n",
      "\t: (160770, 126)\n",
      "Feature: rqa_delta_bp\n",
      "./features/rqa_delta_bp/017.npz does not exist!\n",
      "./features/rqa_delta_bp/021.npz does not exist!\n",
      "./features/rqa_delta_bp/024.npz does not exist!\n",
      "./features/rqa_delta_bp/027.npz does not exist!\n",
      "./features/rqa_delta_bp/040.npz does not exist!\n",
      "\t\trqa_delta_bp shape: (5359, 30, 1, 10)\n",
      "\t: (160770, 10)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subjects = np.array([1, 2, 3, 4])\n",
    "subjects = np.array([3])\n",
    "subjects = np.arange(1,64)\n",
    "# bad_subjects = np.array([17, 21])\n",
    "# subjects = np.setdiff1d(subjects,bad_subjects)\n",
    "\n",
    "subjects = sorted(subjects)\n",
    "\n",
    "\n",
    "# feature_datasets = ['relative_log_power', 'arError', 'stats', 'various']\n",
    "feature_datasets = ['arError', 'relative_log_power', 'stats']\n",
    "feature_datasets = ['autocorrmat']\n",
    "\n",
    "feature_datasets = ['relative_log_power', 'stats', 'rqa_delta_bp' ]\n",
    "\n",
    "cv = get_cv(subjects)\n",
    "\n",
    "col_names = []\n",
    "features = []\n",
    "\n",
    "for jj, feat in enumerate(feature_datasets):    \n",
    "    print(f\"Feature: {feat}\")\n",
    "    temp_features = []\n",
    "    subjs = []\n",
    "    for subject in subjects:\n",
    "        s_file = './features/%s/%s.npz' % (feat, str(subject).zfill(3))\n",
    "        if not os.path.exists(s_file):\n",
    "            print(f\"{s_file} does not exist!\")\n",
    "            continue\n",
    "        a = np.load(s_file)\n",
    "        arr = a['features']\n",
    "        temp_features.append(arr)\n",
    "        subjs.extend([subject]*(arr.shape[0]*arr.shape[1]))\n",
    "    \n",
    "    if feat == 'rqa_delta_bp':\n",
    "        temp_features = np.vstack(temp_features)\n",
    "        print(f'\\t\\t{feat} shape:', temp_features.shape)\n",
    "\n",
    "        flat_shape = (temp_features.shape[2] * temp_features.shape[3], )\n",
    "        temp_features = temp_features.reshape((-1, *flat_shape))\n",
    "        print('\\t:', temp_features.shape)\n",
    "        features.append(temp_features)\n",
    "        \n",
    "    elif feat == 'coherences_transposed':\n",
    "        # Broken\n",
    "        print('\\t:', temp_features.shape)\n",
    "    elif feat == 'autocorrmat':\n",
    "        # Broken\n",
    "        print('\\t:', temp_features.shape)\n",
    "    elif feat == 'stats':\n",
    "        # e.g. stats: (70, 30, 21, 6)\n",
    "        #        (time, 30 twenty second windows = 10 min, 21 channels, 6 stats.)\n",
    "        temp_features = np.vstack(temp_features)\n",
    "        temp_features_copy = np.copy(temp_features)\n",
    "        print(f'\\t\\t{feat} shape:', temp_features.shape)\n",
    "        \n",
    "        xform_features = []\n",
    "        for xform in xform_map:\n",
    "            temp_features = np.take(temp_features_copy, xform, axis=2)\n",
    "            xform_features.append(temp_features)\n",
    "            \n",
    "        # Reshape to (180*30, new_shape)\n",
    "        flat_shape = (temp_features.shape[2] * temp_features.shape[3], )\n",
    "        temp_features = temp_features.reshape((-1, *flat_shape))\n",
    "        print('\\t:', temp_features.shape)\n",
    "\n",
    "        features.append(temp_features)\n",
    "        \n",
    "    elif feat == 'relative_log_power':\n",
    "        # e.g. shape already flattened. e.g. (70, 30, 21*6)\n",
    "        temp_features = np.vstack(temp_features)\n",
    "        temp_features_copy = np.copy(temp_features)\n",
    "\n",
    "        print(f'\\t\\t{feat} shape:', temp_features.shape)\n",
    "        xform_features = []\n",
    "        for xform in xform_map:\n",
    "            temp_features = np.take(temp_features_copy, xform, axis=2)\n",
    "            xform_features.append(temp_features)\n",
    "\n",
    "        flat_shape = (temp_features.shape[2] * temp_features.shape[3], )\n",
    "        temp_features = temp_features.reshape((-1, *flat_shape))\n",
    "        print('\\t:', temp_features.shape)\n",
    "\n",
    "\n",
    "        features.append(temp_features)\n",
    "    \n",
    "    col_names.extend([f'{feat}_{i}' for i in range(temp_features.shape[1])])\n",
    "\n",
    "# features = np.vstack(features)\n",
    "\n",
    "print(len(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.DataFrame(np.hstack(features), columns=col_names)\n",
    "df_train['Subject'] = np.array(subjs)\n",
    "df_train['Subject'] = df_train['Subject'].astype('int')\n",
    "df_train = df_train.drop(df_train[df_train['Subject']==2].index)\n",
    "df_train = df_train.drop(df_train[df_train['Subject']==62].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/SPQR_clinFeats_20190419.csv')\n",
    "df = df.rename({'Unnamed: 0': 'Subject', 'Latency (NR)':'Latency - NR'}, axis='columns')\n",
    "\n",
    "df_resp = df.copy()\n",
    "df_resp = df_resp[['Subject', 'Class', 'Age(resp)', 'Latency - R']]\n",
    "df_resp = df_resp[df_resp['Class'] == 0.]\n",
    "df_resp = df_resp.rename({'Latency - R':'Latency', 'Age(resp)': 'Age'}, axis='columns')\n",
    "df_nresp = df.copy()\n",
    "df_nresp = df_nresp[['Subject', 'Class', 'Age(non-resp)', 'Latency - NR']]\n",
    "df_nresp = df_nresp[df_nresp['Class'] ==1.]\n",
    "df_nresp = df_nresp.rename({'Latency - NR':'Latency', 'Age(non-resp)': 'Age'}, axis='columns')\n",
    "\n",
    "df_all = pd.concat([df_resp, df_nresp])\n",
    "df_all['Subject'] = df_all['Subject'].str.split('_').apply(lambda x:x[0]).astype('int')\n",
    "\n",
    "df_all = df_all.drop(df_all[df_all['Subject']==65].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 22 23 25 26 28 29\n",
      " 30 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 48 49 50 51 52 53 54\n",
      " 55 56 57 58 59 60 61 63]\n",
      "[ 1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 22 23 25 26 28 29\n",
      " 30 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 48 49 50 51 52 53 54\n",
      " 55 56 57 58 59 60 61 63]\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Subject'].unique())\n",
    "print(np.sort(df_all['Subject'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_train, df_all, on='Subject', how='left')\n",
    "merged_df['Class'] = merged_df['Class'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = merged_df.copy()\n",
    "train_data_df = train_data_df.drop(['Class'], axis=1)\n",
    "train_ann_df = merged_df[['Subject','Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "params = {\n",
    "    'task':'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss', 'auc'},\n",
    "    'early_stopping_rounds': 20,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 256,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 3,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = train_data_df[['Age', 'Latency', 'Subject']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subjects = train_data_df[\"Subject\"].unique()\n",
    "subj_classes= df_all.loc[train_data_df['Subject'].isin(unique_subjects), 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17040</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17041</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17042</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17043</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17044</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107725</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107726</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107727</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107728</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107729</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject  Class\n",
       "17040         8      1\n",
       "17041         8      1\n",
       "17042         8      1\n",
       "17043         8      1\n",
       "17044         8      1\n",
       "...         ...    ...\n",
       "107725       45      0\n",
       "107726       45      0\n",
       "107727       45      0\n",
       "107728       45      0\n",
       "107729       45      0\n",
       "\n",
       "[14880 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 10\n",
      "[LightGBM] [Info] Number of positive: 65400, number of negative: 74820\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84\n",
      "[LightGBM] [Info] Number of data points in the train set: 140220, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466410 -> initscore=-0.134563\n",
      "[LightGBM] [Info] Start training from score -0.134563\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.589486\tvalid's auc: 1\n",
      "Fold 2 / 10\n",
      "[LightGBM] [Info] Number of positive: 66030, number of negative: 73470\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84\n",
      "[LightGBM] [Info] Number of data points in the train set: 139500, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.473333 -> initscore=-0.106768\n",
      "[LightGBM] [Info] Start training from score -0.106768\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's binary_logloss: 0.658399\tvalid's auc: 0.721653\n",
      "Fold 3 / 10\n",
      "[LightGBM] [Info] Number of positive: 60990, number of negative: 76260\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82\n",
      "[LightGBM] [Info] Number of data points in the train set: 137250, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444372 -> initscore=-0.223439\n",
      "[LightGBM] [Info] Start training from score -0.223439\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.667421\tvalid's auc: 0.739581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 / 10\n",
      "[LightGBM] [Info] Number of positive: 66450, number of negative: 72450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 138900, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478402 -> initscore=-0.086447\n",
      "[LightGBM] [Info] Start training from score -0.086447\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's binary_logloss: 0.548527\tvalid's auc: 1\n",
      "Fold 5 / 10\n",
      "[LightGBM] [Info] Number of positive: 69540, number of negative: 70770\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82\n",
      "[LightGBM] [Info] Number of data points in the train set: 140310, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495617 -> initscore=-0.017533\n",
      "[LightGBM] [Info] Start training from score -0.017533\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.632916\tvalid's auc: 0.106095\n",
      "Fold 6 / 10\n",
      "[LightGBM] [Info] Number of positive: 58290, number of negative: 81360\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82\n",
      "[LightGBM] [Info] Number of data points in the train set: 139650, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.417401 -> initscore=-0.333453\n",
      "[LightGBM] [Info] Start training from score -0.333453\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.816269\tvalid's auc: 0.694878\n",
      "Fold 7 / 10\n",
      "[LightGBM] [Info] Number of positive: 65070, number of negative: 79740\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82\n",
      "[LightGBM] [Info] Number of data points in the train set: 144810, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.449347 -> initscore=-0.203308\n",
      "[LightGBM] [Info] Start training from score -0.203308\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's binary_logloss: 0.657193\tvalid's auc: 0.713004\n",
      "Fold 8 / 10\n",
      "[LightGBM] [Info] Number of positive: 68460, number of negative: 71790\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 83\n",
      "[LightGBM] [Info] Number of data points in the train set: 140250, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.488128 -> initscore=-0.047496\n",
      "[LightGBM] [Info] Start training from score -0.047496\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.595342\tvalid's auc: 1\n",
      "Fold 9 / 10\n",
      "[LightGBM] [Info] Number of positive: 62460, number of negative: 78090\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 85\n",
      "[LightGBM] [Info] Number of data points in the train set: 140550, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444397 -> initscore=-0.223336\n",
      "[LightGBM] [Info] Start training from score -0.223336\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.621688\tvalid's auc: 1\n",
      "Fold 10 / 10\n",
      "[LightGBM] [Info] Number of positive: 63150, number of negative: 77790\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84\n",
      "[LightGBM] [Info] Number of data points in the train set: 140940, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448063 -> initscore=-0.208500\n",
      "[LightGBM] [Info] Start training from score -0.208500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.614763\tvalid's auc: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dbernardo/.pyenv/versions/3.8.3/envs/eegres383/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "skfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Get unique subjects in the data\n",
    "unique_subjects = train_data_df[\"Subject\"].unique()\n",
    "\n",
    "preds = []\n",
    "metadata = []\n",
    "\n",
    "val_scores = []\n",
    "for fold_id, (train_ids, valid_ids) in enumerate(skfold.split(unique_subjects, subj_classes)):\n",
    "    # Get the subject IDs for the train and validation sets\n",
    "    train_subjects = unique_subjects[train_ids]\n",
    "    valid_subjects = unique_subjects[valid_ids]\n",
    "    \n",
    "    # Split the data and annotations based on the subject IDs\n",
    "    train_data = train_data_df[train_data_df[\"Subject\"].isin(train_subjects)]\n",
    "    valid_data = train_data_df[train_data_df[\"Subject\"].isin(valid_subjects)]\n",
    "    train_ann = train_ann_df[train_ann_df[\"Subject\"].isin(train_subjects)]\n",
    "    valid_ann = train_ann_df[train_ann_df[\"Subject\"].isin(valid_subjects)]\n",
    "\n",
    "    metadata.append([valid_ann, valid_data])\n",
    "    \n",
    "    train_data = train_data.drop(['Subject'], axis=1)\n",
    "    valid_data = valid_data.drop(['Subject'], axis=1)\n",
    "\n",
    "    print(\"Fold %d / %d\" % (fold_id + 1, n_folds))\n",
    "\n",
    "    lgb_train = lgb.Dataset(train_data, train_ann['Class'])\n",
    "    lgb_valid  = lgb.Dataset(valid_data, valid_ann['Class'])\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    gbm = lgb.train(params, lgb_train, num_boost_round=400, \n",
    "                    valid_sets=[lgb_valid], valid_names=['valid'],\n",
    "                    evals_result=res, verbose_eval=-100)\n",
    "    \n",
    "    val_scores.append(res['valid']['auc'][-1])\n",
    "    \n",
    "    \n",
    "    probas = gbm.predict(valid_data)\n",
    "    preds.append(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann = train_ann_df[train_ann_df[\"Subject\"].isin(train_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_val_score: 0.797873\n"
     ]
    }
   ],
   "source": [
    "print(\"avg_val_score: %4f\" % (np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42019505 0.51994958]\n",
      "[0.38438611 0.39310575 0.57311632]\n",
      "[0.40049212 0.44410875 0.50039956]\n",
      "[0.1269504  0.46394633 0.85583883 0.86212766]\n",
      "[0.44625963 0.44844364 0.47358422]\n",
      "[0.37634343 0.47654841]\n",
      "[0.29694708 0.29741739 0.63760355]\n",
      "[0.4395824  0.46062952 0.53926116]\n",
      "[0.40051487 0.50042209]\n",
      "[0.4037943  0.50367065]\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.DataFrame()\n",
    "c = 0\n",
    "for anns, clinvars in metadata:\n",
    "    curr_df = pd.concat([anns, clinvars], axis=1)\n",
    "    curr_df['preds'] = preds[c]\n",
    "    print(np.unique(preds[c]))\n",
    "    metadata_df = pd.concat([metadata_df, curr_df], axis=0)\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.to_csv('spqr_v20230331.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Latency</th>\n",
       "      <th>Subject</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17040</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.503671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17041</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.503671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17042</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.503671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17043</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.503671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17044</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.503671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107725</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.403794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107726</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.403794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107727</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.403794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107728</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.403794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107729</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.403794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14880 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject  Class    Age  Latency  Subject     preds\n",
       "17040         8      1  122.0     56.0        8  0.503671\n",
       "17041         8      1  122.0     56.0        8  0.503671\n",
       "17042         8      1  122.0     56.0        8  0.503671\n",
       "17043         8      1  122.0     56.0        8  0.503671\n",
       "17044         8      1  122.0     56.0        8  0.503671\n",
       "...         ...    ...    ...      ...      ...       ...\n",
       "107725       45      0  230.0      3.0       45  0.403794\n",
       "107726       45      0  230.0      3.0       45  0.403794\n",
       "107727       45      0  230.0      3.0       45  0.403794\n",
       "107728       45      0  230.0      3.0       45  0.403794\n",
       "107729       45      0  230.0      3.0       45  0.403794\n",
       "\n",
       "[14880 rows x 6 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through kfolds\n",
    "all_shap_v = []\n",
    "all_Xv = []\n",
    "all_subjs = []\n",
    "all_yp = []\n",
    "all_yv = []\n",
    "all_ictal = []\n",
    "kfolds_dir = 'kfolds_all_noTD_cork_huh_ucsf'\n",
    "\n",
    "\n",
    "for kf in range(10):\n",
    "    print('#####', kf)\n",
    "    Xv_lst, yp_lst, yv_lst, y_test_ictal_lst, subj_lst, raw_data_cols, curr_shaps = run_kf(kfold=kf, kfolds_dir=kfolds_dir)\n",
    "    \n",
    "\n",
    "    raw_data_cols_plusArt = raw_data_cols + ['artifact_score']\n",
    "    Xv_df = pd.DataFrame(data=Xv_lst, columns=raw_data_cols_plusArt)\n",
    "    Xv_df = Xv_df.fillna(0)\n",
    "    all_Xv.append(Xv_df)\n",
    "\n",
    "    all_shap_v.append(curr_shaps)\n",
    "    all_subjs.append(subj_lst)\n",
    "    all_yp.append(yp_lst)\n",
    "    all_yv.append(yv_lst)\n",
    "    all_ictal.append(y_test_ictal_lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 30, 21, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
